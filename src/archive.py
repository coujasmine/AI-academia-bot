"""
Archive manager for date-based report storage and README index updates.

Saves each run's output to archives/YYYY-MM-DD/ with both a Markdown report
(human-readable on GitHub) and a JSON dump (machine-readable backup).
Automatically maintains a history table in the project README.
"""

import json
import logging
import os
import re
from datetime import datetime
from pathlib import Path

from config.settings import BASE_DIR

logger = logging.getLogger(__name__)

ARCHIVES_DIR = BASE_DIR / "archives"
README_PATH = BASE_DIR / "README.md"


class ArchiveManager:
    """Manages date-based archiving of paper data and report files."""

    def __init__(self, root_dir: Path | None = None):
        self.root_dir = root_dir or ARCHIVES_DIR
        self.today = datetime.now().strftime("%Y-%m-%d")
        self.current_dir = self.root_dir / self.today

    def save(self, papers: list[dict], report_path: Path | None = None) -> Path:
        """Archive papers to a dated folder with JSON + Markdown.

        Args:
            papers: List of normalized paper dicts.
            report_path: Existing report file to copy into the archive.
                         If None, generates a minimal Markdown report.

        Returns:
            Path to the archive directory.
        """
        if not papers:
            logger.info("No papers to archive")
            return self.current_dir

        self.current_dir.mkdir(parents=True, exist_ok=True)

        self._save_json(papers)
        self._save_markdown(papers, report_path)
        self._update_readme_index()

        logger.info("Archive saved to: %s", self.current_dir)
        return self.current_dir

    def _save_json(self, papers: list[dict]):
        """Save raw paper data as JSON for programmatic access."""
        path = self.current_dir / "data.json"
        with open(path, "w", encoding="utf-8") as f:
            json.dump(papers, f, indent=2, ensure_ascii=False)
        logger.info("JSON data saved: %s (%d papers)", path, len(papers))

    def _save_markdown(self, papers: list[dict], report_path: Path | None = None):
        """Save a Markdown report into the archive folder.

        If a report was already generated by report.py, copy its content.
        Otherwise, generate a minimal report inline.
        """
        dest = self.current_dir / "report.md"

        if report_path and report_path.exists():
            content = report_path.read_text(encoding="utf-8")
            dest.write_text(content, encoding="utf-8")
            logger.info("Markdown report archived from: %s", report_path)
        else:
            self._generate_minimal_report(papers, dest)

    def _generate_minimal_report(self, papers: list[dict], dest: Path):
        """Generate a minimal Markdown report when no existing report is available."""
        lines = [
            f"# Paper Report: {self.today}\n",
            f"> **Total Papers:** {len(papers)} | **Source:** FT50 & UTD24\n",
            "---\n",
        ]

        for i, p in enumerate(papers, 1):
            title = p.get("title", "Untitled")
            link = p.get("doi") or p.get("url", "")
            lines.append(f"### {i}. {title}\n")
            lines.append(f"- **Journal:** {p.get('journal_abbr', 'N/A')}")
            authors = p.get("authors", [])
            if authors:
                lines.append(f"- **Authors:** {', '.join(authors[:5])}")
            lines.append(f"- **Date:** {p.get('publication_date', 'N/A')}")
            if link:
                lines.append(f"- **Link:** [{link}]({link})")
            abstract = p.get("abstract", "")
            if abstract:
                if len(abstract) > 300:
                    abstract = abstract[:300] + "..."
                lines.append(f"> {abstract}")
            lines.append("")

        dest.write_text("\n".join(lines), encoding="utf-8")
        logger.info("Minimal Markdown report generated: %s", dest)

    def _update_readme_index(self):
        """Update the history reports table in README.md between archive markers."""
        if not README_PATH.exists():
            logger.warning("README.md not found, skipping index update")
            return

        content = README_PATH.read_text(encoding="utf-8")

        # Check for markers
        pattern = r"(<!-- ARCHIVE_START -->)(.*?)(<!-- ARCHIVE_END -->)"
        if not re.search(pattern, content, flags=re.DOTALL):
            logger.warning(
                "Archive markers (<!-- ARCHIVE_START/END -->) not found in README. "
                "Index not updated."
            )
            return

        # Scan all date directories under archives/
        if not self.root_dir.exists():
            return

        dates = sorted(
            [
                d.name
                for d in self.root_dir.iterdir()
                if d.is_dir() and re.match(r"\d{4}-\d{2}-\d{2}", d.name)
            ],
            reverse=True,
        )

        # Build the table
        table_lines = [
            "## History Reports\n",
            "| Date | Report | Data |",
            "|---|---|---|",
        ]
        for d in dates:
            report_link = f"[Report](archives/{d}/report.md)"
            json_link = f"[JSON](archives/{d}/data.json)"
            table_lines.append(f"| {d} | {report_link} | {json_link} |")

        new_content = "\n".join(table_lines)
        updated = re.sub(
            pattern,
            f"<!-- ARCHIVE_START -->\n\n{new_content}\n\n<!-- ARCHIVE_END -->",
            content,
            flags=re.DOTALL,
        )

        README_PATH.write_text(updated, encoding="utf-8")
        logger.info("README index updated with %d archive entries", len(dates))
